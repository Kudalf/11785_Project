{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ab4fad6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G:\\\\Anaconda\\\\lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
       " '-f',\n",
       " 'C:\\\\Users\\\\User\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-405377be-7a9f-49c8-be8d-e339a3b7c22e.json']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, os\n",
    "import random\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "from data import load_data_instances, DataIterator\n",
    "from model import MultiInferBert\n",
    "import utils\n",
    "from transformers import BertTokenizer\n",
    "import pdb\n",
    "\n",
    "import sys\n",
    "sys.argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dbe9523c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--class_num'], dest='class_num', nargs=None, const=None, default=4, type=<class 'int'>, choices=None, help='label number', metavar=None)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--prefix', type=str, default=\"../../data/\",\n",
    "                    help='dataset and embedding path prefix')\n",
    "parser.add_argument('--model_dir', type=str, default=\"savemodel/\",\n",
    "                    help='model path prefix')\n",
    "parser.add_argument('--task', type=str, default=\"pair\", choices=[\"pair\", \"triplet\"],\n",
    "                    help='option: pair, triplet')\n",
    "parser.add_argument('--mode', type=str, default=\"train\", choices=[\"train\", \"test\"],\n",
    "                    help='option: train, test')\n",
    "parser.add_argument('--dataset', type=str, default=\"res14\", choices=[\"res14\", \"lap14\", \"res15\", \"res16\"],\n",
    "                    help='dataset')\n",
    "parser.add_argument('--max_sequence_len', type=int, default=100,\n",
    "                    help='max length of a sentence')\n",
    "parser.add_argument('--device', type=str, default=\"cpu\",\n",
    "                    help='gpu or cpu')\n",
    "\n",
    "parser.add_argument('--bert_model_path', type=str,\n",
    "                    default=\"pretrained/bert-base-uncased\",\n",
    "                    help='pretrained bert model path')\n",
    "parser.add_argument('--bert_tokenizer_path', type=str,\n",
    "                    default=\"bert-base-uncased\",\n",
    "                    help='pretrained bert tokenizer path')\n",
    "parser.add_argument('--bert_feature_dim', type=int, default=768,\n",
    "                    help='dimension of pretrained bert feature')\n",
    "\n",
    "parser.add_argument('--nhops', type=int, default=1,\n",
    "                    help='inference times')\n",
    "parser.add_argument('--batch_size', type=int, default=3,\n",
    "                    help='bathc size')\n",
    "parser.add_argument('--epochs', type=int, default=100,\n",
    "                    help='training epoch number')\n",
    "parser.add_argument('--class_num', type=int, default=4,\n",
    "                    help='label number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e6cc66c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(prefix='../../data/', model_dir='savemodel/', task='pair', mode='train', dataset='res14', max_sequence_len=200, device='cpu', bert_model_path='pretrained/bert-base-uncased', bert_tokenizer_path='bert-base-uncased', bert_feature_dim=768, nhops=1, batch_size=3, epochs=100, class_num=4)\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args(\"\")\n",
    "print(args)\n",
    "args.class_num = 6\n",
    "args.task = \"triplet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bcda7def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiInferBert(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls_linear): Linear(in_features=1536, out_features=6, bias=True)\n",
       "  (feature_linear): Linear(in_features=1554, out_features=1536, bias=True)\n",
       "  (dropout_output): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(args.bert_tokenizer_path)\n",
    "model_path = \"./savemodel/berttriplet.pt\"\n",
    "model = torch.load(model_path, map_location=torch.device('cpu'), )\n",
    "model.args.max_sequence_len = args.max_sequence_len\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3455d487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is where your actual TODOs start\n",
    "# You will need to implement the Dataset class by your own. You may also implement it similar to HW1P2 (dont require context)\n",
    "# The steps for implementation given below are how we have implemented it.\n",
    "# However, you are welcomed to do it your own way if it is more comfortable or efficient. \n",
    "\n",
    "class AmazonReviews(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, data_path, partition= \"train\"): # You can use partition to specify train or dev\n",
    "        \n",
    "        file = data_path\n",
    "        self.data = pd.read_csv(data_path).to_numpy()\n",
    "       \n",
    "       \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "\n",
    "        product_id, sentence = self.data[ind]\n",
    "\n",
    "\n",
    "        return product_id, sentence\n",
    "    \n",
    "    def collate_fn(batch):\n",
    "        \n",
    "        \n",
    "        \n",
    "        list_of_review_dicts = []\n",
    "        for product_id, sentence in batch:\n",
    "            list_of_review_dicts.append({'id': product_id, 'sentence': sentence, 'triples': []})\n",
    "        \n",
    "        #The output here is [{'id': product_id, 'sentence': sentence, 'triples': []}, ...]\n",
    "        return list_of_review_dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5faeec71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size:  3\n",
      "Train dataset samples = 10, batches = 4\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "\n",
    "root = \"../../data/amazon/small_dataset.csv\" \n",
    "\n",
    "train_data = AmazonReviews(root, 'train')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=AmazonReviews.collate_fn)# TODO: Define the train loader. Remember to pass in a parameter (function) for the collate_fn argument \n",
    "\n",
    "print(\"Batch size: \", batch_size)\n",
    "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1785b2f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'FOURTH_ID', 'sentence': \"The grinder's initial build quality and workmanship seemed good considering the price. However, as someone new to using angle grinders, I was unaware of the risk of damaging the motor via overheating. Within 24 hours of opening the box, I had damaged the device by overworking it while grinding concrete.\", 'triples': []}, {'id': 'FIFTH_ID', 'sentence': \"Looked fantastic, lovely box , plenty spare disks etc. Finally got to use it cutting 20mm paving stones , lasted ten minutes - my own stupid fault - did not notice the 110V and plugged it in to 240V- I'm sure it would have been fine like the rest of my MAKITA tools - cut the stone perfectly in the ten minutes it worked, and I'm impressed it did not burn my hands off\", 'triples': []}, {'id': 'TENTH_ID', 'sentence': \"I got this for my boyfriend for Christmas and he has used it almost twice a day, every day since. It's very sturdy and durable. Make sure you put it on a stable surface before using. We originally put it on top of our roll-away dishwasher and it was so strong that it made the entire thing shake and move around. IT has suction cups on the bottom to keep it from scooting across the counter though so that's a good feature.\", 'triples': []}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test code for checking shapes and return arguments of the train\n",
    "for data in train_loader:\n",
    "    x = data \n",
    "    \n",
    "    print(x)\n",
    " \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "08ed59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pseudo_labels(pseudo_sentence_pack, sentence_ids, tokens, lengths, masks, sens_lens, token_ranges, aspect_tags, tags):\n",
    "    \n",
    "    \n",
    "    \n",
    "    all_ids = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_lengths = []\n",
    "    all_sens_lengths = []\n",
    "    all_token_ranges = []\n",
    "\n",
    "    all_preds.append(preds)\n",
    "    all_labels.append(tags)\n",
    "    all_lengths.append(lengths)\n",
    "    all_sens_lengths.extend(sens_lens)\n",
    "    all_token_ranges.extend(token_ranges)\n",
    "    all_ids.extend(sentence_ids)\n",
    "\n",
    "    all_preds = torch.cat(all_preds, dim=0).cpu().tolist()\n",
    "    all_labels = torch.cat(all_labels, dim=0).cpu().tolist()\n",
    "    all_lengths = torch.cat(all_lengths, dim=0).cpu().tolist()\n",
    "\n",
    "\n",
    "    metric = utils.Metric(args, all_preds, all_labels, all_lengths, all_sens_lengths, all_token_ranges, ignore_index=-1)\n",
    "    precision, recall, f1 = metric.score_uniontags()\n",
    "    \n",
    "    aspect_results = metric.score_aspect()\n",
    "    opinion_results = metric.score_opinion()\n",
    "    \n",
    "    for i in range(len(metric.predictions)):\n",
    "            \n",
    "        predicted_aspect_spans = metric.get_spans(metric.predictions[i], metric.sen_lengths[i], metric.tokens_ranges[i], 1)\n",
    "        predicted_opinion_spans = metric.get_spans(metric.predictions[i], metric.sen_lengths[i], metric.tokens_ranges[i], 2)\n",
    "        if metric.args.task == 'pair':\n",
    "            predicted_tuples = metric.find_pair(metric.predictions[i], predicted_aspect_spans, predicted_opinion_spans, metric.tokens_ranges[i])\n",
    "        elif metric.args.task == 'triplet':\n",
    "            predicted_tuples = metric.find_triplet(metric.predictions[i], predicted_aspect_spans, predicted_opinion_spans, metric.tokens_ranges[i])\n",
    "        \n",
    "        pseudo_sentence_pack[i]['triples'].extend(predicted_tuples)\n",
    "        \n",
    "    return pseudo_sentence_pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "da40e742",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_sentence_packs = []\n",
    "for review_dicts in train_loader:\n",
    "    \n",
    "    unlabeled_sentence_pack = review_dicts\n",
    "    \n",
    "    instances = load_data_instances(unlabeled_sentence_pack, args)\n",
    "   \n",
    "    testset = DataIterator(instances, args)\n",
    "    \n",
    "    sentence_ids, tokens, lengths, masks, sens_lens, token_ranges, aspect_tags, tags = testset.get_batch(0)\n",
    "   \n",
    "    pred = model(tokens, masks)\n",
    "   \n",
    "    preds = torch.argmax(pred, dim=3)\n",
    "    \n",
    "\n",
    "   \n",
    "    pseudo_labeled_pack = get_pseudo_labels(unlabeled_sentence_pack, sentence_ids, tokens, lengths, masks, sens_lens, token_ranges, aspect_tags, tags)\n",
    "    \n",
    "    pseudo_sentence_packs.extend(pseudo_labeled_pack)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "416ed5d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'SIXTH_ID',\n",
       "  'sentence': \"Wow. That's all I can say. This is possibly the best vacuum I have ever owned. I usually buy the cheaper ones from Walmart So I don't have much to compare this to when it comes down to other highquality name brand vaccuums.\",\n",
       "  'triples': [[11, 11, 10, 10, 5]]},\n",
       " {'id': 'FIFTH_ID',\n",
       "  'sentence': \"Looked fantastic, lovely box , plenty spare disks etc. Finally got to use it cutting 20mm paving stones , lasted ten minutes - my own stupid fault - did not notice the 110V and plugged it in to 240V- I'm sure it would have been fine like the rest of my MAKITA tools - cut the stone perfectly in the ten minutes it worked, and I'm impressed it did not burn my hands off\",\n",
       "  'triples': [[3, 3, 1, 2, 5], [7, 7, 5, 6, 5], [16, 16, 5, 6, 5]]},\n",
       " {'id': 'TENTH_ID',\n",
       "  'sentence': \"I got this for my boyfriend for Christmas and he has used it almost twice a day, every day since. It's very sturdy and durable. Make sure you put it on a stable surface before using. We originally put it on top of our roll-away dishwasher and it was so strong that it made the entire thing shake and move around. IT has suction cups on the bottom to keep it from scooting across the counter though so that's a good feature.\",\n",
       "  'triples': [[45, 45, 50, 50, 3]]},\n",
       " {'id': 'EIGHTH_ID',\n",
       "  'sentence': 'I used a moderately priced Dyson for the last few years, until the motor went out on it. I purchased the Hoover in the hopes that it was better than the one I previously had, years ago. I have three big dogs, so lots of dog hair; unfortunately, the Hoover doesn?t do a good job vacuuming.',\n",
       "  'triples': [[4, 5, 3, 3, 5], [45, 46, 43, 43, 5]]},\n",
       " {'id': 'THIRD_ID',\n",
       "  'sentence': \"Wow to 799 pcs of tools!!! I did not sit there and count them all but the box is huge and included many tools inside. I did not use them all but glad i bought this set because i won't need to make many trips to local hardware store. Because i have everything right here with me. The luggage style tool case is super handy to pulling/rolling it around without lifting it up. It provided all the basic tools that I needed for household repairs. Have put several tools to the test and they have held up well! I placed everything into my toolbox rather than keeping them in the case however, the case was sturdy and held the tools snuggly into it.\",\n",
       "  'triples': [[17, 17, 19, 19, 5],\n",
       "   [58, 58, 64, 64, 5],\n",
       "   [58, 58, 115, 115, 5],\n",
       "   [60, 61, 64, 64, 5],\n",
       "   [60, 61, 115, 115, 5],\n",
       "   [113, 113, 115, 115, 5]]},\n",
       " {'id': 'NINTH_ID',\n",
       "  'sentence': 'Lid comes loose during blending no matter how tight it is put on and it leaks making a splatter mess. I spend much time cleaning base. Also the drinking lids are hard to get on straight. Now after 2 months it smells like sour milk. The leaks have gone inside the unit so I?m sure won?t last long.',\n",
       "  'triples': [[0, 0, 2, 2, 3], [0, 0, 8, 8, 3], [28, 29, 31, 31, 3]]},\n",
       " {'id': 'SECOND_ID',\n",
       "  'sentence': 'There overall set is good. You got so many when paying so less.',\n",
       "  'triples': [[2, 2, 4, 4, 5]]},\n",
       " {'id': 'FOURTH_ID',\n",
       "  'sentence': \"The grinder's initial build quality and workmanship seemed good considering the price. However, as someone new to using angle grinders, I was unaware of the risk of damaging the motor via overheating. Within 24 hours of opening the box, I had damaged the device by overworking it while grinding concrete.\",\n",
       "  'triples': [[1, 1, 8, 8, 5], [4, 4, 8, 8, 5]]},\n",
       " {'id': 'SEVENTH_ID',\n",
       "  'sentence': 'This vacuum is AMAZING. I vacuumed with my old vacuum, then let my roomba vacuum, and immediate after I vacuumed with this one. I had 3/4 of a dirt bin full of dust & dirt. My carpets and rugs are completely rejuvenated.',\n",
       "  'triples': [[1, 1, 3, 3, 5], [38, 38, 41, 41, 5]]},\n",
       " {'id': 'FIRST_ID',\n",
       "  'sentence': \"The hardware is fine. Screen looks great and is responsive enough, and the phone has enough power to do everything I've asked of it, but...\\nIt comes bundled with reams of Samsung's dreadful software which is awful and cannot be uninstalled. Samsung also go out of their way to make it difficult to disable their garbage and use third party or google's options. I will keep the phone for a while but would not buy again.\",\n",
       "  'triples': [[1, 1, 3, 3, 5],\n",
       "   [1, 1, 6, 6, 5],\n",
       "   [4, 4, 6, 6, 5],\n",
       "   [4, 4, 9, 9, 5],\n",
       "   [33, 33, 32, 32, 3]]}]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_sentence_packs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a2821cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]' 'this' 'vacuum' 'is' 'amazing' '.' 'i' 'vacuum' '##ed' 'with'\n",
      " 'my' 'old' 'vacuum' ',' 'then' 'let' 'my' 'room' '##ba' 'vacuum' ','\n",
      " 'and' 'immediate' 'after' 'i' 'vacuum' '##ed' 'with' 'this' 'one' '.' 'i'\n",
      " 'had' '3' '/' '4' 'of' 'a' 'dirt' 'bin' 'full' 'of' 'dust' '&' 'dirt' '.'\n",
      " 'my' 'carpets' 'and' 'rug' '##s' 'are' 'completely' 're' '##ju' '##ven'\n",
      " '##ated' '.' '[SEP]']\n",
      "This vacuum is AMAZING. I vacuumed with my old vacuum, then let my roomba vacuum, and immediate after I vacuumed with this one. I had 3/4 of a dirt bin full of dust & dirt. My carpets and rugs are completely rejuvenated.\n",
      "[[1, 1, 3, 3, 5], [38, 38, 41, 41, 5]]\n"
     ]
    }
   ],
   "source": [
    "index = 8\n",
    "sentence = pseudo_sentence_packs[index]['sentence']\n",
    "triplets = pseudo_sentence_packs[index]['triples']\n",
    "\n",
    "encoding = tokenizer.encode(sentence)\n",
    "words = tokenizer.convert_ids_to_tokens(encoding)\n",
    "words = np.asarray(words)\n",
    "\n",
    "print(words)\n",
    "print(sentence)\n",
    "print(triplets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_triplets(label_sentence_pack):\n",
    "    #TODO\n",
    "    \n",
    "    return NotImplemented\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
